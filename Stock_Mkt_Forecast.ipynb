{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project forecasts US stock market by the performance of stock markets in other countries.\n",
    "# The goals of this project\n",
    "1. Predicting US stock market based on information from interenational stock markets.\n",
    "2. Applying various statistical/machine learning methods for prediction, and compares their performances.\n",
    "3. Providing insightful investment advices.\n",
    "\n",
    "# Findings\n",
    "1. Stock markets in other countries have predictive power for US stock market.\n",
    "2. OLS and Ridge regressions provide the best prediction.\n",
    "3. The data set is not large enough (215 data points in tatal) for the machine learning methods to outperform regressions. \n",
    "4. The performance comparison is summarized at the end of the project.\n",
    "5. The stock markets in France, Portugal, Italy and Greece are negatively related to the US stock movement. Thus, investing in these countries is good hedging strategy.\n",
    "\n",
    "\n",
    "# 1. The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\compat\\pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>US</th>\n",
       "      <th>JP</th>\n",
       "      <th>GB</th>\n",
       "      <th>DE</th>\n",
       "      <th>FR</th>\n",
       "      <th>IT</th>\n",
       "      <th>CA</th>\n",
       "      <th>ES</th>\n",
       "      <th>PT</th>\n",
       "      <th>GR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1997-10-31</td>\n",
       "      <td>3.664936</td>\n",
       "      <td>1.072069</td>\n",
       "      <td>-0.228268</td>\n",
       "      <td>4.269542</td>\n",
       "      <td>3.901979</td>\n",
       "      <td>3.315279</td>\n",
       "      <td>-4.936632</td>\n",
       "      <td>7.586259</td>\n",
       "      <td>4.156334</td>\n",
       "      <td>-0.979569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1997-11-30</td>\n",
       "      <td>2.393549</td>\n",
       "      <td>-8.643722</td>\n",
       "      <td>5.208389</td>\n",
       "      <td>5.635678</td>\n",
       "      <td>4.800509</td>\n",
       "      <td>9.279251</td>\n",
       "      <td>2.825756</td>\n",
       "      <td>4.428291</td>\n",
       "      <td>5.778483</td>\n",
       "      <td>0.379869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1997-12-31</td>\n",
       "      <td>-0.109771</td>\n",
       "      <td>8.596826</td>\n",
       "      <td>5.081450</td>\n",
       "      <td>4.247254</td>\n",
       "      <td>5.276067</td>\n",
       "      <td>11.507212</td>\n",
       "      <td>0.011348</td>\n",
       "      <td>9.513052</td>\n",
       "      <td>13.316926</td>\n",
       "      <td>-5.861094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1998-01-31</td>\n",
       "      <td>6.378283</td>\n",
       "      <td>1.214592</td>\n",
       "      <td>5.622851</td>\n",
       "      <td>5.894949</td>\n",
       "      <td>7.591167</td>\n",
       "      <td>5.480019</td>\n",
       "      <td>5.689910</td>\n",
       "      <td>10.765061</td>\n",
       "      <td>10.668401</td>\n",
       "      <td>1.692631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1998-02-28</td>\n",
       "      <td>5.107415</td>\n",
       "      <td>-1.825650</td>\n",
       "      <td>3.596323</td>\n",
       "      <td>7.289553</td>\n",
       "      <td>11.518873</td>\n",
       "      <td>20.824999</td>\n",
       "      <td>6.363625</td>\n",
       "      <td>13.718557</td>\n",
       "      <td>13.697838</td>\n",
       "      <td>34.594548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date        US        JP        GB        DE         FR         IT  \\\n",
       "0 1997-10-31  3.664936  1.072069 -0.228268  4.269542   3.901979   3.315279   \n",
       "1 1997-11-30  2.393549 -8.643722  5.208389  5.635678   4.800509   9.279251   \n",
       "2 1997-12-31 -0.109771  8.596826  5.081450  4.247254   5.276067  11.507212   \n",
       "3 1998-01-31  6.378283  1.214592  5.622851  5.894949   7.591167   5.480019   \n",
       "4 1998-02-28  5.107415 -1.825650  3.596323  7.289553  11.518873  20.824999   \n",
       "\n",
       "         CA         ES         PT         GR  \n",
       "0 -4.936632   7.586259   4.156334  -0.979569  \n",
       "1  2.825756   4.428291   5.778483   0.379869  \n",
       "2  0.011348   9.513052  13.316926  -5.861094  \n",
       "3  5.689910  10.765061  10.668401   1.692631  \n",
       "4  6.363625  13.718557  13.697838  34.594548  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model, tree, ensemble, neighbors, neural_network\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "# The data is the monthly stock returns of 10 developed countries. Augmented dickey fuller test shows there is no unit root.\n",
    "# The data starts at Aug. 1997 and ends at Sep. 2015.\n",
    "df = pd.read_csv('stock_data.csv')\n",
    "df.date = pd.to_datetime(df.date)\n",
    "# The first column is the date, and the second column is US stock return, which is the variable we are interested in.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The past information of the US and other countries are used for forecasting US stock market. \n",
    "# Create lag variables\n",
    "for i in [1,2,3]:\n",
    "    df_lag = df.iloc[:,-10:].drop(df.index[-1:])\n",
    "    df_lag.loc[-1] = \"NULL\" \n",
    "    df_lag.index = df_lag.index + 1  \n",
    "    df_lag = df_lag.sort_index() \n",
    "    df_lag.columns = ['US_L{}'.format(i), 'JP_L{}'.format(i), 'GB_L{}'.format(i), 'DE_L{}'.format(i), \n",
    "                      'FR_L{}'.format(i), 'IT_L{}'.format(i), 'CA_L{}'.format(i), 'ES_L{}'.format(i),\n",
    "                      'PT_L{}'.format(i), 'GR_L{}'.format(i)]\n",
    "    df = pd.concat([df, df_lag], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dependent and independent variables\n",
    "Y = df.iloc[3:,1]\n",
    "X = df.iloc[3:,2:]\n",
    "\n",
    "# Take 80% sample as the training set, and 20% sample as the test set\n",
    "# Because it is time-series data, it is not propriate using random sampling to split training/test sets. \n",
    "# The training set must be at the begining of the data, and test set is at the end.\n",
    "Y_train, Y_test = Y.iloc[:172], Y.iloc[172:]\n",
    "X_train, X_test = X.iloc[:172,:], X.iloc[172:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for presenting the coefficient of determination and root-mean-square error\n",
    "# The input is the fitting result for a method\n",
    "def ShowResult(Fit_Result):\n",
    "    RMSE_train = sqrt(mean_squared_error(Y_train, Fit_Result.predict(X_train)))\n",
    "    print('The RMSE for the training set: ', RMSE_train)\n",
    "    Score_train = Fit_Result.score(X_train, Y_train)\n",
    "    print('The coefficient of determination for the training set: ', Score_train)\n",
    "    RMSE_test = sqrt(mean_squared_error(Y_test, Fit_Result.predict(X_test)))\n",
    "    print('The RMES for the test set: ', RMSE_test)\n",
    "    Score_test = Fit_Result.score(X_test, Y_test)\n",
    "    print('The coefficient of determination for the test set: ', Score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. The Models\n",
    "In this section, different machine learning models are applied. The coefficient of determination and root-mean-square error are used to compare the prediction performance of the models.\n",
    "## 2.1 Regression\n",
    "### 2.1.1 Ordinary Least Square\n",
    "The linear OLS is the benchmark model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE for the training set:  1.720586221735386\n",
      "The coefficient of determination for the training set:  0.8752219241464316\n",
      "The RMES for the test set:  1.4468699686979707\n",
      "The coefficient of determination for the test set:  0.724885922738558\n"
     ]
    }
   ],
   "source": [
    "OLS = linear_model.LinearRegression()\n",
    "OLS_Result = OLS.fit(X_train, Y_train)\n",
    "ShowResult(OLS_Result)\n",
    "OLS_RMSE_test = sqrt(mean_squared_error(Y_test, OLS_Result.predict(X_test)))\n",
    "OLS_score = OLS_Result.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE for the training set:  2.093006913223005\n",
      "The coefficient of determination for the training set:  0.8153596016947813\n",
      "The RMES for the test set:  1.5516014640309304\n",
      "The coefficient of determination for the test set:  0.6836162496984587\n"
     ]
    }
   ],
   "source": [
    "Lasso = linear_model.Lasso()\n",
    "Lasso_Result = Lasso.fit(X_train, Y_train)\n",
    "ShowResult(Lasso_Result)\n",
    "Lasso_RMSE_test = sqrt(mean_squared_error(Y_test, Lasso_Result.predict(X_test)))\n",
    "Lasso_score = Lasso_Result.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE for the training set:  1.7205897860334354\n",
      "The coefficient of determination for the training set:  0.8752214071752884\n",
      "The RMES for the test set:  1.446319175607337\n",
      "The coefficient of determination for the test set:  0.7250953432032068\n"
     ]
    }
   ],
   "source": [
    "Ridge = linear_model.Ridge()\n",
    "Ridge_Result = Ridge.fit(X_train, Y_train)\n",
    "ShowResult(Ridge_Result)\n",
    "Ridge_score = Ridge_Result.score(X_test, Y_test)\n",
    "Ridge_RMSE_test = sqrt(mean_squared_error(Y_test, Ridge_Result.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.4 Least Angle Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE for the training set:  2.32158831868825\n",
      "The coefficient of determination for the training set:  0.7728274659507648\n",
      "The RMES for the test set:  2.501962267134681\n",
      "The coefficient of determination for the test set:  0.1773495877990554\n"
     ]
    }
   ],
   "source": [
    "Lars = linear_model.Lars()\n",
    "Lars_Result = Lars.fit(X_train, Y_train)\n",
    "ShowResult(Lars_Result)\n",
    "Lars_RMSE_test = sqrt(mean_squared_error(Y_test, Lars_Result.predict(X_test)))\n",
    "Lars_score = Lars_Result.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Tree-based Models\n",
    "### 2.2.1 Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE for the training set:  1.9610306824501542\n",
      "The coefficient of determination for the training set:  0.8379107621658095\n",
      "The RMES for the test set:  2.1974089423824448\n",
      "The coefficient of determination for the test set:  0.3654357760521424\n"
     ]
    }
   ],
   "source": [
    "# Different max depth is tested, and when it is 3, the model achieved the best prediction result.\n",
    "# The deeper the tree is, the more likely it's overfitted, and the out-of-sample prediction would be worse.\n",
    "# So, the depth must be carefully chosen for the best prediction performance.\n",
    "Tree = tree.DecisionTreeRegressor(max_depth = 3) \n",
    "\n",
    "Tree_Result = Tree.fit(X_train, Y_train)\n",
    "ShowResult(Tree_Result)\n",
    "Tree_RMSE_test = sqrt(mean_squared_error(Y_test, Tree_Result.predict(X_test)))\n",
    "Tree_score = Tree_Result.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Ensemble Models\n",
    "### 2.3.1 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE for the training set:  2.240059682242528\n",
      "The coefficient of determination for the training set:  0.7885028197390198\n",
      "The RMES for the test set:  2.1157600166355808\n",
      "The coefficient of determination for the test set:  0.41171656507151255\n"
     ]
    }
   ],
   "source": [
    "# max_depth is chosen as 2 for the best prediction result.\n",
    "RF = ensemble.RandomForestRegressor(max_depth = 2) \n",
    "\n",
    "RF_Result = RF.fit(X_train, Y_train)\n",
    "ShowResult(RF_Result)\n",
    "RF_RMSE_test = sqrt(mean_squared_error(Y_test, RF_Result.predict(X_test)))\n",
    "RF_score = RF_Result.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 Extramemly Randomized Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE for the training set:  2.4494055503203582\n",
      "The coefficient of determination for the training set:  0.747124474712785\n",
      "The RMES for the test set:  1.761742444024856\n",
      "The coefficient of determination for the test set:  0.5921141463387014\n"
     ]
    }
   ],
   "source": [
    "ET = ensemble.ExtraTreesRegressor(max_depth = 2) \n",
    "ET_Result = ET.fit(X_train, Y_train)\n",
    "ShowResult(ET_Result)\n",
    "ET_RMSE_test = sqrt(mean_squared_error(Y_test, ET_Result.predict(X_test)))\n",
    "ET_score = ET_Result.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.3 AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE for the training set:  1.4126960311663856\n",
      "The coefficient of determination for the training set:  0.9158831786838089\n",
      "The RMES for the test set:  1.8864000658606825\n",
      "The coefficient of determination for the test set:  0.5323494880417199\n"
     ]
    }
   ],
   "source": [
    "AdaBoost = ensemble.AdaBoostRegressor() \n",
    "AdaBoost_Result = AdaBoost.fit(X_train, Y_train)\n",
    "ShowResult(AdaBoost_Result)\n",
    "AdaBoost_RMSE_test = sqrt(mean_squared_error(Y_test, AdaBoost_Result.predict(X_test)))\n",
    "AdaBoost_score = AdaBoost_Result.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.4 Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE for the training set:  1.076597628142613\n",
      "The coefficient of determination for the training set:  0.9511468873178895\n",
      "The RMES for the test set:  1.9566612664725753\n",
      "The coefficient of determination for the test set:  0.4968643343555857\n"
     ]
    }
   ],
   "source": [
    "Bagging = ensemble.BaggingRegressor() \n",
    "Bagging_Result = Bagging.fit(X_train, Y_train)\n",
    "ShowResult(Bagging_Result)\n",
    "Bagging_RMSE_test = sqrt(mean_squared_error(Y_test, Bagging_Result.predict(X_test)))\n",
    "Bagging_score = Bagging_Result.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.5 Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE for the training set:  0.3499006538889304\n",
      "The coefficient of determination for the training set:  0.9948397004717816\n",
      "The RMES for the test set:  1.9005098131089149\n",
      "The coefficient of determination for the test set:  0.5253275335203691\n"
     ]
    }
   ],
   "source": [
    "GradientB = ensemble.GradientBoostingRegressor() \n",
    "GradientB_Result = GradientB.fit(X_train, Y_train)\n",
    "ShowResult(GradientB_Result)\n",
    "GradientB_RMSE_test = sqrt(mean_squared_error(Y_test, GradientB_Result.predict(X_test)))\n",
    "GradientB_score = GradientB_Result.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE for the training set:  2.930335157889267\n",
      "The coefficient of determination for the training set:  0.6380738240285253\n",
      "The RMES for the test set:  1.8382644606132141\n",
      "The coefficient of determination for the test set:  0.55591123068175\n"
     ]
    }
   ],
   "source": [
    "# Leaf size doesn't matter\n",
    "KNN = neighbors.KNeighborsRegressor(n_neighbors = 10) \n",
    "KNN_Result = KNN.fit(X_train, Y_train)\n",
    "ShowResult(KNN_Result)\n",
    "KNN_RMSE_test = sqrt(mean_squared_error(Y_test, KNN_Result.predict(X_test)))\n",
    "KNN_score = KNN_Result.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE for the training set:  0.361099726428446\n",
      "The coefficient of determination for the training set:  0.9945040886166395\n",
      "The RMES for the test set:  2.493459527860084\n",
      "The coefficient of determination for the test set:  0.18293152356879183\n",
      "The RMES for the test set:  2.493459527860084\n",
      "The coefficient of determination for the test set:  0.18293152356879183\n"
     ]
    }
   ],
   "source": [
    "NNW = neural_network.MLPRegressor() \n",
    "NNW_Result = NNW.fit(X_train, Y_train)\n",
    "ShowResult(NNW_Result)\n",
    "NNW_RMSE_test = sqrt(mean_squared_error(Y_test, NNW_Result.predict(X_test)))\n",
    "print('The RMES for the test set: ', NNW_RMSE_test)\n",
    "NNW_score = NNW_Result.score(X_test, Y_test)\n",
    "print('The coefficient of determination for the test set: ', NNW_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Summary\n",
    "Prediction Performance Comparison. The following table shows the coefficient of determination and root-mean-square error of each method for the test set. OLS and Ridge have the best prediction performance. The machine learning methods do not perform well due to small data size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R^2</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>OLS</th>\n",
       "      <td>0.724886</td>\n",
       "      <td>1.446870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>0.683616</td>\n",
       "      <td>1.551601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.725095</td>\n",
       "      <td>1.446319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lars</th>\n",
       "      <td>0.177350</td>\n",
       "      <td>2.501962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.365436</td>\n",
       "      <td>2.197409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.411717</td>\n",
       "      <td>2.115760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTree</th>\n",
       "      <td>0.592114</td>\n",
       "      <td>1.761742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.532349</td>\n",
       "      <td>1.886400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging</th>\n",
       "      <td>0.496864</td>\n",
       "      <td>1.956661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <td>0.525328</td>\n",
       "      <td>1.900510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.555911</td>\n",
       "      <td>1.838264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural Network</th>\n",
       "      <td>0.182932</td>\n",
       "      <td>2.493460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        R^2      RMSE\n",
       "OLS                0.724886  1.446870\n",
       "Lasso              0.683616  1.551601\n",
       "Ridge              0.725095  1.446319\n",
       "Lars               0.177350  2.501962\n",
       "Decision Tree      0.365436  2.197409\n",
       "Random Forest      0.411717  2.115760\n",
       "ExtraTree          0.592114  1.761742\n",
       "AdaBoost           0.532349  1.886400\n",
       "Bagging            0.496864  1.956661\n",
       "Gradient Boosting  0.525328  1.900510\n",
       "KNN                0.555911  1.838264\n",
       "Neural Network     0.182932  2.493460"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Results = np.array([[OLS_score, OLS_RMSE_test], [Lasso_score, Lasso_RMSE_test], \n",
    "                   [Ridge_score, Ridge_RMSE_test], [Lars_score, Lars_RMSE_test], \n",
    "                   [Tree_score, Tree_RMSE_test], [RF_score, RF_RMSE_test], \n",
    "                   [ET_score, ET_RMSE_test], [AdaBoost_score, AdaBoost_RMSE_test], \n",
    "                   [Bagging_score, Bagging_RMSE_test], [GradientB_score, GradientB_RMSE_test], \n",
    "                   [KNN_score, KNN_RMSE_test], [NNW_score, NNW_RMSE_test]])\n",
    "df_Result = pd.DataFrame(Results, ['OLS', 'Lasso', 'Ridge', 'Lars', 'Decision Tree', 'Random Forest',\n",
    "                                   'ExtraTree', 'AdaBoost', 'Bagging', 'Gradient Boosting', 'KNN', 'Neural Network'],\n",
    "                        ['R^2', 'RMSE'])\n",
    "df_Result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
